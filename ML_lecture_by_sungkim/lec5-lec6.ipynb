{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lec 5-1 : logistic classification 의 가설 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류의 종류\n",
    "- 스팸 메일\n",
    "- 페이스북 피드\n",
    "- 신용카드 사기 거래\n",
    "\n",
    "1 또는 0 으로 예측. \n",
    "\n",
    "주식 시장의 상승 하락을 분류 할 수 도 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ z = Wx + b$$\n",
    "를 만들어 g(z) 가 0에서 1사이의 결과값을 내주는 함수를 찾음  \n",
    "#### sigmoid(or logistic function)  \n",
    "$$g(x) = \\frac{1}{(1+e^{-W^TX})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "항상 0과 1사이의 값을 가질 수 있게 됨.  \n",
    "logistic 함수의 가장 중요한 부분"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/5-1.png)\n",
    "- 함수가 linear regression일 때는 cost function 의 그래프가 2차 포물선으로 비교적 단순\n",
    "- But, logistic 함수의 경우에는 cost function 의 그래프가 오른쪽과 같이 울퉁불퉁\n",
    "- logistic cost 함수의 경우 local minimum에 걸려, global minimum을 못찾을 수 있음.\n",
    "- 따라서, hypothesis를 바꿨으므로 cost function도 바꿔야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### new cost function for logistic\n",
    "$$  cost(W) = \\frac{1}{m}\\sum c(H(x), y)$$\n",
    "$$  c(H(x), y) = \n",
    "\\begin{cases}\n",
    "-log(H(x)), &\\mbox{ : y = 1} \\\\\n",
    "-log(1 - H(x)), &\\mbox{ : y = 0}\n",
    "\\end{cases}$$\n",
    "\n",
    "c함수는 y 가 1, 0일 경우로 2가지로 나눠서 정의.  \n",
    "exp로 구부러진 함수를 log함수로 잡는 것이 기본적인 아이디어\n",
    "\n",
    "$$C(H(x), y) = ylog(H(x)) - (1-y)log(1-H(x))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimize cost - Gradient descent algorithm\n",
    "가중치에서 alpha를 곱해준 cost(W)의 미분값을 빼줌  \n",
    "(텐서플로우의 경우 gradientdescentoptimizer 를 사용하면 자동 해결)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lec 6-1 : Softmax regression 기본 개념 소개"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression\n",
    "- 기존의 linear regression 의 형태는 binary classification 이 안됨  \n",
    "- 0과 1로 결과값이 나올 수 있는 함수를 고안 -> sigmoid or logistic 을 제안\n",
    "- 그림으로 표현할 경우 아래와 같음\n",
    "![image.png](img/5-2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/5-3.png)\n",
    "- 학점 A,B,C를 주는 경우\n",
    "- A 이거나 아니거나 , B이거나 아니거나, C이거나 아니거나 3개의 각각 다른 선을 그어 구분"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](img/5-4.png)\n",
    "- 위와 같이 각각 3개의 공식을 만들어 3개의 선을 그을 수 있으나 공식 및 코드가 복잡해짐\n",
    "- 하나의 matrix 형태로 만들어서 곱을 할 경우, 위와 같이 3 by 1 형태의 vector형태로 결과값이 나옴\n",
    "- 최종 벡터 값에서 A, B, C 의 값 중 하나를 골라 주는 것이 softmax 함수"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### softmax function\n",
    "![image.png](img/5-5.png)\n",
    "- 최종 벡터값(가장 좌측)에서 시그모이드 함수를 적용 - 이를 다시 one-hot-encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost function\n",
    "![image.png](img/5-6.png)\n",
    "- cross entropy\n",
    "- L이 실제 정답, S(Y)는 y hat, 두 개사이의 차이가 얼마나 되는지 크로스 엔트로피 함수를 통해 구하게 됨. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=VRnubDzIy3A (여기서부터 들을 것)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
